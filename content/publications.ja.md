+++
title = "Publications"
slug = "publications"
languageCode = "ja"
+++

## International Journal Papers

1. Y. Obinata, K. Kawaharazuka, **N. Kanazawa**, N. Yamaguchi, N. Tsukamoto, I. Yanokura, S. Kitagawa, K. Okada, M. Inaba.
"Situation classification of living environment by daily life support robot using pre-trained large-scale vision-language model", Advanced Robotics (AR), vol.39, no.7, pp.323-337, 2025.
[Paper Link](https://doi.org/10.1080/01691864.2025.2487608 )

1. **N. Kanazawa**, K. Kawaharazuka, Y. Obinata, K. Okada, M. Inaba.
"Real-world cooking robot system from recipes based on food state recognition using foundation models and PDDL", Advanced Robotics (AR), vol.38, no.18, pp.1318-1334, 2024.
[Paper Link](https://doi.org/10.1080/01691864.2024.2407136 ) [Arxiv Link](https://arxiv.org/abs/2410.02874 ) [Project Page](https://kanazawanaoaki.github.io/cook-from-recipe-pddl/ ) [Video](https://youtu.be/3bQRTAKV0wM?si=jCCfpHHxBXbrA2-_ )

1. K. Kawaharazuka, Y. Obinata, **N. Kanazawa**, N. Tsukamoto, K. Okada, M. Inaba.
"Reflex-Based Open-Vocabulary Navigation without Prior Knowledge Using Omnidirectional Camera and Multiple Vision-Language Models", Advanced Robotics (AR), vol.38, no.18, pp.1307-1317, 2024.
[Paper Link](https://doi.org/10.1080/01691864.2024.2393409 ) [Arxiv Link](https://arxiv.org/abs/2408.11380 ) [Project Page](https://haraduka.github.io/omnidirectional-vlm/ ) [Video](https://youtu.be/T2Uezkpu5u4?si=Jf6yMUZMsdIFU0E8 )

1. K. Kawaharazuka, Y. Obinata, **N. Kanazawa**, K. Okada, M. Inaba.
"Robotic Environmental State Recognition with Pre-Trained Vision-Language Models and Black-Box Optimization", Advanced Robotics (AR), vol.38, no.18, pp.1255-1264, 2024.
[Paper Link](https://doi.org/10.1080/01691864.2024.2366995 ) [Arxiv Link](https://arxiv.org/abs/2409.17519 ) [Project Page](https://haraduka.github.io/vlm-bbo/ ) [Video](https://youtu.be/aOoQcEdVb6M?si=sMOoERErn4VUEE4l )

1. K. Kawaharazuka, **N. Kanazawa**, Y. Obinata, K. Okada, M. Inaba.
"Continuous Object State Recognition for Cooking Robots Using Pre-Trained Vision-Language Models and Black-box Optimization", IEEE Robotics and Automation Letters (RAL), vol.9, no.5, pp.4059-4066, 2024. (presented at Humanoids2024),
[Paper Link](https://doi.org/10.1109/LRA.2024.3375257 ) [Arxiv Link](https://arxiv.org/abs/2403.08239 ) [Project Page](https://haraduka.github.io/continuous-state-recognition/ ) [Video](https://www.youtube.com/watch?v=480caUHXrE0 )

1. K. Kawaharazuka, **N. Kanazawa**, K. Okada, M. Inaba. "Self-Supervised Learning of Visual Servoing for Low-Rigidity Robots Considering Temporal Body Changes", IEEE Robotics and Automation Letters (RAL), vol.7, no.3, pp.7881-7887, 2022. **SICE International Young Authors Award (SIYA-IROS2022)**, (presented at IROS2022),
[Paper Link](https://ieeexplore.ieee.org/document/9806167/ ) [Arxiv Link](https://arxiv.org/abs/2405.11798 ) [Video](https://www.youtube.com/watch?v=ulWgQTVDGQA )

## International Conference Proceedings (Peer Reviewed)

1. S. Kim, **N. Kanazawa**, S. Hasegawa, K. Kawaharazuka, K. Okada.
"Front Hair Styling Robot System Using Path Planning for Root-Centric Strand Adjustment", in Proceedings of the 2025 IEEE/SICE International Symposium on System Integration (SII2025), 2025. **Best Student Paper Finalist**
[Paper Link](https://ieeexplore.ieee.org/document/10871088/ ) [Arxive Link](https://arxiv.org/abs/2501.10991 ) [Video](https://www.youtube.com/watch?v=AUBmOXsnqbg )

1. K. Kawaharazuka, Y. Obinata, **N. Kanazawa**, K. Okada, M. Inaba.
"Robotic State Recognition with Image-to-Text Retrieval Task of Pre-Trained Vision-Language Model and Black-Box Optimization", in Proceedings of the 2024 IEEE-RAS International Conference on Humanoid Robots (Humanoids2024), 2024.
[Paper Link](https://ieeexplore.ieee.org/document/10769848 ) [Arxive Link](https://arxiv.org/abs/2410.22707 )

1. Y. Obinata, H. Jia, K. Kawaharazuka, **N. Kanazawa**, K. Okada
"Remote Life Support Robot Interface System for Global Task Planning and Local Action Expansion Using Foundation Models", in Proceedings of the 2024 IEEE-RAS International Conference on Humanoid Robots (Humanoids2024), 2024.
[Paper Link](https://ieeexplore.ieee.org/document/10769852 ) [Arxive Link](https://arxiv.org/abs/2411.10038 ) [Video](https://youtu.be/bM0w69k0LM8?si=YwbjSqW216hyQoUK )

1. Open X-Embodiment Collaboration.
"Open X-Embodiment: Robotic Learning Datasets and RT-X Models", in Proceedings of the 2024 IEEE International Conference on Robotics and Automation (ICRA2024), 2024. **Best Conference Paper Award**, **Finalists of Best Paper Award in Robot Manipulation**
[Paper Link](https://doi.org/10.1109/ICRA57147.2024.10611477 ) [Arxiv Link](https://robotics-transformer-x.github.io/paper.pdf ) [Project Page](https://robotics-transformer-x.github.io/ )

1. K. Kawaharazuka, Y. Obinata, **N. Kanazawa**, K. Okada, M. Inaba.
"Robotic Applications of Pre-Trained Vision-Language Models to Various Recognition Behaviors", in Proceedings of the 2023 IEEE-RAS International Conference on Humanoid Robots (Humanoids2023), pp.458-465, 2023.
[Paper Link](https://doi.org/10.1109/Humanoids57100.2023.10375211 ) [Arxiv Link](https://arxiv.org/abs/2303.05674 )

1. K. Kawaharazuka, **N. Kanazawa**, Y. Obinata, K. Okada, M. Inaba.
"Daily Assistive View Control Learning of Low-Cost Low-Rigidity Robot via Large-Scale Vision-Language Model", in Proceedings of the 2023 IEEE-RAS International Conference on Humanoid Robots (Humanoids2023), pp.452-457, 2023.
[Paper Link](https://doi.org/10.1109/Humanoids57100.2023.10375239 ) [Arxiv Link](https://arxiv.org/abs/2312.07451 )

1. Y. Obinata, K. Kawaharazuka, **N. Kanazawa**, N. Yamaguchi, N. Tsukamoto, I. Yanokura, S. Kitagawa, K. Shinjo, K. Okada, M. Inaba.
"Semantic Scene Difference Detection in Daily Life Patroling by Mobile Robots Using Pre-Trained Large-Scale Vision-Language Model", in Proceedings of the 2023 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS2023), pp.3228-3233, 2023.
**IEEE RAS Japan Joint Chapter Young Award (2023)**, **SICE International Young Authors Award (SIYA-IROS2023)**
[Paper Link](https://doi.org/10.1109/IROS55552.2023.10342467 ) [Arxiv Link](https://arxiv.org/abs/2309.16552 )

1. **N. Kanazawa**, K. Kawaharazuka, Y. Obinata, K. Okada, M. Inaba.
"Recognition of Heat-Induced Food State Changes by Time-Series Use of Vision-Language Model for Cooking Robot", in Proceedings of the 18th International Conference on Intellignet Autonomous Systems (IAS2023), pp.547-560, 2023.
[Paper Link](https://doi.org/10.1007/978-3-031-44851-5_42 ) [Arxiv Link](https://arxiv.org/abs/2309.01528 )

2. K. Kawaharazuka, Y. Obinata, **N. Kanazawa**, K. Okada, M. Inaba.
"VQA-based Robotic State Recognition Optimized with Genetic Algorithm", in Proceedings of the 2023 IEEE International Conference on Robotics and Automation (ICRA2023), pp.8306-8311, 2023.
[Paper Link](https://doi.org/10.1109/ICRA48891.2023.10160390) [Arxiv Link](https://arxiv.org/abs/2303.05052 )

3. K. Kawaharazuka, **N. Kanazawa**, K. Okada, M. Inaba.
"Learning-Based Wiping Behavior of Low-Rigidity Robots Considering Various Surface Materials and Task Definitions", in Proceedings of the 2022 IEEE-RAS International Conference on Humanoid Robots (Humanoids2022), pp.919-924, 2022.
[Paper Link](https://doi.org/10.1109/Humanoids53995.2022.10000172 ) [Arxiv Link](https://arxiv.org/abs/2403.11198 ) [Video](https://www.youtube.com/watch?v=N47IXZ6Q0io )

## International Workshop

1. K. Kawaharazuka, Y. Obinata, **N. Kanazawa**, N. Tsukamoto, K. Okada.
"Reflexive Open-Vocabulary Navigation without Prior Knowledge Using Omnidirectional Camera and Multiple Vision-Language Models", 2024 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS2024), 2024, (Workshop on Environment Dynamics Matters: Embodied Navigation to Movable Objects) **Excellent Practice Award**

1. Open X-Embodiment Collaboration.
"Open X-Embodiment: Robotic Learning Datasets and RT-X Models", Proceedings of the 2023 Neural Information Processing Systems (NeurIPS2023), 2023, (6th Robot Learning Workshop: Pretraining, Fine-Tuning, and Generalization with Large Scale Models)

1. Open X-Embodiment Collaboration.
"Open X-Embodiment: Robotic Learning Datasets and RT-X Models", Proceedings of the 2023 Conference on Robot Learning (CoRL2023), 2023, (2nd Workshop on Language and Robot Learning: Language as Grounding)

1. Open X-Embodiment Collaboration.
"Open X-Embodiment: Robotic Learning Datasets and RT-X Models", Proceedings of the 2023 Conference on Robot Learning (CoRL2023), 2023, (Towards Generalist Robots: Learning Paradigms for Scalable Skill Acquisition)


## arXiv
1. K. Kawaharazuka, Y. Obinata, **N. Kanazawa**, K. Okada, M. Inaba.
"Binary State Recognition by Robots using Visual Question Answering of Pre-Trained Vision-Language Model", arXiv preprint arXiv:2310.16405, 2023.
[Arxiv Link](https://arxiv.org/abs/2310.16405 )

1. Y. Obinata, **N. Kanazawa**, K. Kawaharazuka, I. Yanokura, S. Kim, K. Okada, M. Inaba.
"Foundation Model based Open Vocabulary Task Planning and Executive System for General Purpose Service Robots", arXiv preprint arXiv:2308.03357, 2023.
[Arxiv Link](https://arxiv.org/abs/2308.03357 ) [Video](https://www.youtube.com/watch?app=desktop&v=fiN4Zibk6Sg )

## Domestic Journal Papers

1. 河原塚 健人, 大日方 慶樹, **金沢 直晃**, 岡田 慧, 稲葉 雅幸.
大規模視覚-言語モデルと遺伝的アルゴリズムに基づくロボットのための状態認識, 日本ロボット学会誌 (JRSJ), vol.42, no.3, pp.259-265, 2024.
[Paper Link](https://www.rsj.or.jp/pub/jrsj/advpub/231213-04.html )

2. **金沢 直晃**, 河原塚 健人, 大日方 慶樹, 岡田 慧, 稲葉 雅幸.
料理レシピ記述解析と視覚 - 言語モデルの時系列利用による食材状態変化認識に基づくロボットの調理作業実行, 日本ロボット学会誌 (JRSJ), vol.42, no.3, pp.266-273, 2024.
[Paper Link](https://www.rsj.or.jp/pub/jrsj/advpub/231213-05.html )

## Domestic Conference Proceedings (Peer Reviewed)
1. 河原塚 健人, 大日方 慶樹, **金沢 直晃**, 岡田 慧, 稲葉 雅幸.
視覚-言語モデルと遺伝的アルゴリズムに基づくロボットのための離散・連続状態認識, in 第28回ロボティクスシンポジア予稿集 (ROBOSYM2023), pp. 34-35, 2023.

2. 大日方 慶樹, 河原塚 健人, **金沢 直晃**, 山口 直也, 塚本 直人, 矢野倉 伊織, 北川 晋吾, 岡田 慧, 稲葉 雅幸.
事前学習済み視覚-言語モデルを用いた巡回ロボットの長期記憶に基づく日常環境の状況分類, in 第28回ロボティクスシンポジア予稿集 (ROBOSYM2023), pp. 36-37, 2023.

3. **金沢 直晃**, 河原塚 健人, 大日方 慶樹, 岡田 慧, 稲葉 雅幸.
調理支援ロボットの視覚-言語モデル時系列利用によるレシピ記述からの食材状態変化認識, in 第28回ロボティクスシンポジア予稿集 (ROBOSYM2023), pp. 66-67, 2023. **第13回ロボティクスシンポジア研究奨励賞**.

## Domestic Conference Proceedings (No Reviewed)

1. 河原塚 健人, 大日方 慶樹, **金沢 直晃**, 塚本 直人, 岡田 慧.
全天球カメラと事前学習済み視覚-言語モデルによる事前知識を必要としない反射型Open Vocabulary Navigation, in 第25回SICEシステムインテグレーション部門講演会概要集 (SI2024), 1F6-04, 2024, **優秀講演賞**
1. 河原塚 健人, **金沢 直晃**, 大日方 慶樹, 岡田 慧.
大規模視覚-言語モデルによる調理ロボットの時系列食材状態認識, in 第42回日本ロボット学会学術講演会講演論文集 (RSJ2024), 3D2-03, 2024.
1. 大日方 慶樹, 賈 浩宇, 河原塚 健人, **金沢 直晃**, 岡田 慧.
あいまいな生活支援ロボット動作記述のVLMとARデバイスを用いた提示と指示による展開, in 第42回日本ロボット学会学術講演会講演論文集 (RSJ2024), 3D3-02, 2024.
1. 大日方 慶樹, 塚本 直人, 河原塚 健人, **金沢 直晃**, 岡田 慧, 稲葉 雅幸.
生活支援ロボットの現場知識に基づくオンライン動作プログラム展開, in 第38回人工知能学会全国大会講演論文集 (JSAI2024), 4E1-GS-8-04, 2024.
1. **金沢 直晃**, 河原塚 健人, 大日方 慶樹, 岡田 慧, 稲葉 雅幸.
基盤モデルと古典プランニングを用いたレシピ記述からの実世界調理計画認識実行ロボットシステム, in 言語処理学会第30回年次大会 (NLP2024), E1-3, 2024.
1. **金沢 直晃**, 河原塚 健人, 大日方 慶樹, 岡田 慧, 稲葉 雅幸.
対象物状態中心の調理行動記述に基づくレシピからの卵料理の実世界調理実行ロボットシステム,
in 第24回SICEシステムインテグレーション部門講演会講演概要集 (SI2023), 3G2-08, 2023. **優秀講演賞**
1. 金 淳暁, **金沢 直晃**, 長谷川 峻, 河原塚 健人, 岡田 慧, 稲葉 雅幸.
生活支援ロボットを用いた視覚と力覚に基づく頭髪ブラッシング動作生成に関する研究,
in 第24回SICEシステムインテグレーション部門講演会講演概要集 (SI2023), 3F1-08, 2023.
1. **金沢 直晃**, 河原塚 健人, 大日方 慶樹, 岡田 慧, 稲葉 雅幸.
調理ロボットのための基盤モデル利用によるレシピ記述からの卵料理の食材状態変化認識と動作シーケンス生成,
in 第41回日本ロボット学会学術講演会講演論文集 (RSJ2023), 1K3-03, 2023.
1. 大日方 慶樹, **金沢 直晃**, 河原塚 健人, 矢野倉 伊織, 金 淳暁, 岡田 慧, 稲葉 雅幸.
大規模言語モデルによるタスク実行管理器生成法とRoboCup JapanOpen @Home League GPSRタスクへの応用,
in 第41回日本ロボット学会学術講演会講演論文集 (RSJ2023), 1K4-05, 2023. **日本ロボット学会第5回優秀講演賞**
1. **金沢 直晃**, 河原塚 健人, 石田 寛和, 岡田 慧, 稲葉 雅幸.
反復自動データ収集を用いた模倣学習による環境設備操作タスクの実現,
in 日本機械学会ロボティクス・メカトロニクス講演会'23 講演論文集 (ROBOMECH2023), 1P1-D05, 2023.
2. 大日方 慶樹, 河原塚 健人, **金沢 直晃**, 山口 直也, 塚本 直人, 矢野倉 伊織, 北川 晋吾, 岡田 慧, 稲葉 雅幸.
大規模視覚-言語モデルとチャットインタフェースを用いた生活環境の分類とロボットタスクマッピングシステム,
in 日本機械学会ロボティクス・メカトロニクス講演会'23 講演論文集 (ROBOMECH2023), 1P1-D06, 2023.
3. 河原塚 健人, 大日方 慶樹, **金沢 直晃**, 岡田 慧, 稲葉 雅幸.
日常生活支援ロボットに向けた大規模視覚-言語モデルと進化的計算に基づく状態認識,
in 第37回人工知能学会全国大会講演論文集 (JSAI2023), 3G1-OS-24a-04, 2023.
4. **金沢 直晃**, 河原塚 健人, 大日方 慶樹, 岡田 慧, 稲葉 雅幸.
大規模基盤モデル利用による料理レシピ記述からの食材状態変化を考慮した調理認識計画行動ロボットシステム,
in 第37回人工知能学会全国大会講演論文集 (JSAI2023), 3G1-OS-24a-02, 2023.
5. 河原塚 健人, **金沢 直晃**, 岡田 慧, 稲葉 雅幸.
低剛性ロボットの身体変化を考慮した自律的視覚サーボ学習,
in 第23回SICEシステムインテグレーション部門講演会講演概要集 (SI2022), 3P2-H07, 2022.
6. **金沢 直晃**, 山口 直也, 北川 晋吾, 岡田 慧, 稲葉 雅幸.
小型センシングモジュールによる知能化家電とロボットが連携して食関連生活支援を行うマルチエージェント型ハウスキーピングシステム,
in 第23回SICEシステムインテグレーション部門講演会講演概要集 (SI2022), 3P2-B18, 2022.
7. **金沢 直晃**, 河原塚 健人, 石田 寛和, 岡田 慧, 稲葉 雅幸.
ロボットの反復 pick-and-place 自動データ収集によるOne-Shot 教示把持動作スキル学習システム,
in 第40回日本ロボット学会学術講演会講演論文集 (RSJ2022), 3F1-03, 2022.
8. **金沢 直晃**, 河原塚 健人, 岡田 慧, 稲葉 雅幸.
Parametric Bias を用いた食材特徴を考慮可能な調理ロボットの包丁切断操作学習,
in 第40回日本ロボット学会学術講演会講演論文集 (RSJ2022), 4I1-06, 2022.
9. **金沢 直晃**, 河原塚 健人, 岡田 慧, 稲葉 雅幸.
Parametric Biasを用いた調理ロボットの包丁切断操作における食材特徴学習,
in 日本機械学会ロボティクス・メカトロニクス講演会'22 講演論文集 (ROBOMECH2022), 1A1-T11, 2022.
10. **金沢 直晃**, 北川 晋吾, 室岡 貴之, 岡田 慧, 稲葉 雅幸.
テンプレートマッチング認識とプリミティブ動作により状態を考慮した家電操作を行うロボットシステム,
in 第22回SICEシステムインテグレーション部門講演会講演概要集 (SI2021), 1G2-02, 2021. **優秀講演賞**
11. **金沢 直晃**, 岡田 慧, 稲葉 雅幸.
台車移動型双腕ロボットによるカレー調理行動実行システム,
in 第39回日本ロボット学会学術講演会講演論文集 (RSJ2021), 2H3-05, 2021.
12. **金沢 直晃**, 北川 晋吾, 室岡 貴之, 岡田 慧, 稲葉 雅幸.
調理道具を扱う双腕ロボットによる野菜皮剥き切断操作の認識行動実現システム,
in 第21回SICEシステムインテグレーション部門講演会講演概要集 (SI2020), 3E2-08, 2020.

## Awards (Publication)

1. S. Kim, **N. Kanazawa**, S. Hasegawa, K. Kawaharazuka, K. Okada.
**Best Student Paper Finalist**, 2025 IEEE/SICE International Symposium on System Integration (SII2025), 2025.1.24.

1. 河原塚 健人, 大日方 慶樹, **金沢 直晃**, 塚本 直人, 岡田 慧.
**優秀講演賞**, 第25回SICEシステムインテグレーション部門講演会 (SI2024), 2024.12.20.

1. K. Kawaharazuka, Y. Obinata, **N. Kanazawa**, N. Tsukamoto, K. Okada.
**Excellent Practice Award**, 2024 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS2024), (Workshop on Environment Dynamics Matters: Embodied Navigation to Movable Objects), 2024.10.14.

1. Open X-Embodiment Collaboration
**Finalists of Best Paper Award in Robot Manipulation**, Proceedings of the 2024 IEEE International Conference on Robotics and Automation (ICRA2024), 2024.5.16.

1. Open X-Embodiment Collaboration
**Best Conference Paper Award**, Proceedings of the 2024 IEEE International Conference on Robotics and Automation (ICRA2024), 2024.5.16.

1. **金沢 直晃**, 河原塚 健人, 大日方 慶樹, 岡田 慧, 稲葉 雅幸.
**優秀講演賞**, 第24回SICEシステムインテグレーション部門講演会講演概要集 (SI2023), 2023.12.16.

1. **金沢 直晃**.
**第13回ロボティクスシンポジア研究奨励賞**, 第28回ロボティクスシンポジア (ROBOSYM2023), 2023.9.13.

2. **金沢 直晃**, 北川 晋吾, 室岡 貴之, 岡田 慧, 稲葉 雅幸.
**優秀講演賞**, 第22回 計測自動制御学会 システムインテグレーション部門講演会 (SI2021)  2021.12.24.

## Awards and Experiences (Others)
1. Team JSK: Y. Obinata, **N. Kanazawa**, S. Kim, K. Kawaharazuka, I. Yanokura, S. Kitagawa. **First Place (GPSR task in DSPL)**, RoboCup@Home JapanOpen2022, 2023.03.06-09.
2. Team 4: 稲富翔伍, **金沢直晃**, 牧原昂志, 籾山陽紀, 渡部泰樹(五十音順). "柔軟物体操作のための世界モデルの構築と実環境への適用可能性の検証", **最優秀賞**, 東京大学 集中講義 世界モデルと知能 最終課題発表会 口頭発表, 2022.05.25. [Link](https://world-model.t.u-tokyo.ac.jp/ )
3. SFP2019黒板消しロボットチーム, **チームラボ賞**, GUGEN2019.12.08. [Link](https://gugen.jp/result/2019.html), [Product Link](https://gugen.jp/subscriptions/work/871 )
4. **twilio 賞**, TRUNK HACKATHON in OSAKA 2019. 2019.03.16-17.
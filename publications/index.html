<!doctype html><html lang=en><head><title>Publications · Naoaki Kanazawa</title><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=color-scheme content="light dark"><meta name=author content="Naoaki Kanazawa"><meta name=description content="International Journal Papers Link to heading K. Kawaharazuka, N. Kanazawa, K. Okada, M. Inaba. &ldquo;Self-Supervised Learning of Visual Servoing for Low-Rigidity Robots Considering Temporal Body Changes&rdquo;, IEEE Robotics and Automation Letters (RAL), vol. 7, no. 3, pp. 7881-7887, 2022. SICE International Young Authors Award (SIYA-IROS2022), (presented at IROS2022), Paper Link Domestic Journal Papers Link to heading 河原塚 健人, 大日方 慶樹, 金沢 直晃, 岡田 慧, 稲葉 雅幸. 大規模視覚-言語モデルと遺伝的アルゴリズムに基づくロボットのための状態認識 (in press), 日本ロボット学会誌 (JRSJ), 2023."><meta name=keywords content="blog,developer,personal"><meta name=twitter:card content="summary"><meta name=twitter:title content="Publications"><meta name=twitter:description content="International Journal Papers Link to heading K. Kawaharazuka, N. Kanazawa, K. Okada, M. Inaba. &ldquo;Self-Supervised Learning of Visual Servoing for Low-Rigidity Robots Considering Temporal Body Changes&rdquo;, IEEE Robotics and Automation Letters (RAL), vol. 7, no. 3, pp. 7881-7887, 2022. SICE International Young Authors Award (SIYA-IROS2022), (presented at IROS2022), Paper Link Domestic Journal Papers Link to heading 河原塚 健人, 大日方 慶樹, 金沢 直晃, 岡田 慧, 稲葉 雅幸. 大規模視覚-言語モデルと遺伝的アルゴリズムに基づくロボットのための状態認識 (in press), 日本ロボット学会誌 (JRSJ), 2023."><meta property="og:title" content="Publications"><meta property="og:description" content="International Journal Papers Link to heading K. Kawaharazuka, N. Kanazawa, K. Okada, M. Inaba. &ldquo;Self-Supervised Learning of Visual Servoing for Low-Rigidity Robots Considering Temporal Body Changes&rdquo;, IEEE Robotics and Automation Letters (RAL), vol. 7, no. 3, pp. 7881-7887, 2022. SICE International Young Authors Award (SIYA-IROS2022), (presented at IROS2022), Paper Link Domestic Journal Papers Link to heading 河原塚 健人, 大日方 慶樹, 金沢 直晃, 岡田 慧, 稲葉 雅幸. 大規模視覚-言語モデルと遺伝的アルゴリズムに基づくロボットのための状態認識 (in press), 日本ロボット学会誌 (JRSJ), 2023."><meta property="og:type" content="article"><meta property="og:url" content="https://kanazawanaoaki.github.io/publications/"><meta property="article:section" content><link rel=canonical href=https://kanazawanaoaki.github.io/publications/><link rel=preload href="/fonts/forkawesome-webfont.woff2?v=1.2.0" as=font type=font/woff2 crossorigin><link rel=stylesheet href=/css/coder.min.ea4c355c5f9913809f506132a80bf3fab84f2679dee370f334f7385a36d24c38.css integrity="sha256-6kw1XF+ZE4CfUGEyqAvz+rhPJnne43DzNPc4WjbSTDg=" crossorigin=anonymous media=screen><link rel=stylesheet href=/css/coder-dark.min.a00e6364bacbc8266ad1cc81230774a1397198f8cfb7bcba29b7d6fcb54ce57f.css integrity="sha256-oA5jZLrLyCZq0cyBIwd0oTlxmPjPt7y6KbfW/LVM5X8=" crossorigin=anonymous media=screen><link rel=icon type=image/svg+xml href=/images/my-favicon.svg sizes=any><link rel=icon type=image/png href=/images/my-favicon-32.ico sizes=32x32><link rel=icon type=image/png href=/images/my-favicon-16.ico sizes=16x16><link rel=apple-touch-icon href=/images/apple-touch-icon.png><link rel=apple-touch-icon sizes=180x180 href=/images/apple-touch-icon.png><link rel=manifest href=/site.webmanifest><link rel=mask-icon href=/images/safari-pinned-tab.svg color=#5bbad5></head><body class="preload-transitions colorscheme-auto"><div class=float-container><a id=dark-mode-toggle class=colorscheme-toggle><i class="fa fa-adjust fa-fw" aria-hidden=true></i></a></div><main class=wrapper><nav class=navigation><section class=container><a class=navigation-title href=/>Naoaki Kanazawa</a>
<input type=checkbox id=menu-toggle>
<label class="menu-button float-right" for=menu-toggle><i class="fa fa-bars fa-fw" aria-hidden=true></i></label><ul class=navigation-list><li class=navigation-item><a class=navigation-link href=/about/>About</a></li><li class=navigation-item><a class=navigation-link href=/publications/>Publications</a></li><li class=navigation-item><a class=navigation-link href=/contact/>Contact me</a></li><li class="navigation-item menu-separator"><span>|</span></li><li class=navigation-item><a href=/ja/publications/>日本語</a></li></ul></section></nav><div class=content><section class="container page"><article><header><h1 class=title><a class=title-link href=https://kanazawanaoaki.github.io/publications/>Publications</a></h1></header><h2 id=international-journal-papers>International Journal Papers
<a class=heading-link href=#international-journal-papers><i class="fa fa-link" aria-hidden=true title="Link to heading"></i>
<span class=sr-only>Link to heading</span></a></h2><ol><li>K. Kawaharazuka, <strong>N. Kanazawa</strong>, K. Okada, M. Inaba. &ldquo;Self-Supervised Learning of Visual Servoing for Low-Rigidity Robots Considering Temporal Body Changes&rdquo;, IEEE Robotics and Automation Letters (RAL), vol. 7, no. 3, pp. 7881-7887, 2022. <strong>SICE International Young Authors Award (SIYA-IROS2022)</strong>, (presented at IROS2022), <a href=https://ieeexplore.ieee.org/document/9806167/ class=external-link target=_blank rel=noopener>Paper Link</a></li></ol><h2 id=domestic-journal-papers>Domestic Journal Papers
<a class=heading-link href=#domestic-journal-papers><i class="fa fa-link" aria-hidden=true title="Link to heading"></i>
<span class=sr-only>Link to heading</span></a></h2><ol><li><p>河原塚 健人, 大日方 慶樹, <strong>金沢 直晃</strong>, 岡田 慧, 稲葉 雅幸.
大規模視覚-言語モデルと遺伝的アルゴリズムに基づくロボットのための状態認識 (in press), 日本ロボット学会誌 (JRSJ), 2023.</p></li><li><p><strong>金沢 直晃</strong>, 河原塚 健人, 大日方 慶樹, 岡田 慧, 稲葉 雅幸.
料理レシピ記述解析と視覚 - 言語モデルの時系列利用による食材状態変化認識に基づくロボットの調理作業実行 (in press), 日本ロボット学会誌 (JRSJ), 2023.</p></li></ol><h2 id=international-conference-proceedings-peer-reviewed>International Conference Proceedings (Peer Reviewed)
<a class=heading-link href=#international-conference-proceedings-peer-reviewed><i class="fa fa-link" aria-hidden=true title="Link to heading"></i>
<span class=sr-only>Link to heading</span></a></h2><ol><li><p><strong>N. Kanazawa</strong>, K. Kawaharazuka, Y. Obinata, K. Okada, M. Inaba.
&ldquo;Recognition of Heat-Induced Food State Changes by Time-Series Use of Vision-Language Model for Cooking Robot&rdquo; (in press), in Proceedings of the 18th International Conference on Intellignet Autonomous Systems (IAS2023), 2023. <a href=https://arxiv.org/abs/2309.01528 class=external-link target=_blank rel=noopener>Paper Link</a></p></li><li><p>K. Kawaharazuka, Y. Obinata, <strong>N. Kanazawa</strong>, K. Okada, M. Inaba.
&ldquo;VQA-based Robotic State Recognition Optimized with Genetic Algorithm&rdquo;, in Proceedings of the 2023 IEEE International Conference on Robotics and Automation (ICRA2023), pp. 8306-8311, 2023. <a href=https://arxiv.org/abs/2303.05052 class=external-link target=_blank rel=noopener>Paper Link</a></p></li><li><p>K. Kawaharazuka, <strong>N. Kanazawa</strong>, K. Okada, M. Inaba.
&ldquo;Learning-Based Wiping Behavior of Low-Rigidity Robots Considering Various Surface Materials and Task Definitions&rdquo;, in Proceedings of the 2022 IEEE-RAS International Conference on Humanoid Robots (HUMANOIDS2022), pp. 919-924, 2022. <a href=https://doi.org/10.1109/Humanoids53995.2022.10000172 class=external-link target=_blank rel=noopener>Paper Link</a></p></li></ol><h2 id=domestic-conference-proceedings-peer-reviewed>Domestic Conference Proceedings (Peer Reviewed)
<a class=heading-link href=#domestic-conference-proceedings-peer-reviewed><i class="fa fa-link" aria-hidden=true title="Link to heading"></i>
<span class=sr-only>Link to heading</span></a></h2><ol><li><p>河原塚 健人, 大日方 慶樹, <strong>金沢 直晃</strong>, 岡田 慧, 稲葉 雅幸.
視覚-言語モデルと遺伝的アルゴリズムに基づくロボットのための離散・連続状態認識, in 第28回ロボティクスシンポジア予稿集 (ROBOSYM23J), pp. 34-35, 2023.</p></li><li><p>大日方 慶樹, 河原塚 健人, <strong>金沢 直晃</strong>, 山口 直也, 塚本 直人, 矢野倉 伊織, 北川 晋吾, 岡田 慧, 稲葉 雅幸.
事前学習済み視覚-言語モデルを用いた巡回ロボットの長期記憶に基づく日常環境の状況分類, in 第28回ロボティクスシンポジア予稿集 (ROBOSYM23J), pp. 36-37, 2023.</p></li><li><p><strong>金沢 直晃</strong>, 河原塚 健人, 大日方 慶樹, 岡田 慧, 稲葉 雅幸.
調理支援ロボットの視覚-言語モデル時系列利用によるレシピ記述からの食材状態変化認識, in 第28回ロボティクスシンポジア予稿集 (ROBOSYM23J), pp. 66-67, 2023.</p></li></ol><h2 id=domestic-conference-proceedings-no-reviewed>Domestic Conference Proceedings (No Reviewed)
<a class=heading-link href=#domestic-conference-proceedings-no-reviewed><i class="fa fa-link" aria-hidden=true title="Link to heading"></i>
<span class=sr-only>Link to heading</span></a></h2><ol><li><strong>金沢 直晃</strong>, 河原塚 健人, 石田 寛和, 岡田 慧, 稲葉 雅幸.
反復自動データ収集を用いた模倣学習による環境設備操作タスクの実現, in 日本機械学会ロボティクス・メカトロニクス講演会'23 講演論文集 (ROBOMECH23J), 1P1-D05, 2023.</li><li>大日方 慶樹, 河原塚 健人, <strong>金沢 直晃</strong>, 山口 直也, 塚本 直人, 矢野倉 伊織, 北川 晋吾, 岡田 慧, 稲葉 雅幸.
大規模視覚-言語モデルとチャットインタフェースを用いた生活環境の分類とロボットタスクマッピングシステム, in 日本機械学会ロボティクス・メカトロニクス講演会'23 講演論文集 (ROBOMECH23J), 1P1-D06, 2023.</li><li>河原塚 健人, 大日方 慶樹, <strong>金沢 直晃</strong>, 岡田 慧, 稲葉 雅幸.
日常生活支援ロボットに向けた大規模視覚-言語モデルと進化的計算に基づく状態認識, in 第37回人工知能学会全国大会講演論文集 (JSAI23J), 3G1-OS-24a-04, 2023.</li><li><strong>金沢 直晃</strong>, 河原塚 健人, 大日方 慶樹, 岡田 慧, 稲葉 雅幸.
大規模基盤モデル利用による料理レシピ記述からの食材状態変化を考慮した調理認識計画行動ロボットシステム, in 第37回人工知能学会全国大会講演論文集 (JSAI23J), 3G1-OS-24a-02, 2023.</li><li>河原塚 健人, <strong>金沢 直晃</strong>, 岡田 慧, 稲葉 雅幸.
低剛性ロボットの身体変化を考慮した自律的視覚サーボ学習, in 第23回SICEシステムインテグレーション部門講演会講演概要集 (SI22J), 3P2-H07, 2022.</li><li><strong>金沢 直晃</strong>, 山口 直也, 北川 晋吾, 岡田 慧, 稲葉 雅幸.
小型センシングモジュールによる知能化家電とロボットが連携して食関連生活支援を行うマルチエージェント型ハウスキーピングシステム, in 第23回SICEシステムインテグレーション部門講演会講演概要集 (SI22J), 3P2-B18, 2022.</li><li><strong>金沢 直晃</strong>, 河原塚 健人, 石田 寛和, 岡田 慧, 稲葉 雅幸.
ロボットの反復 pick-and-place 自動データ収集によるOne-Shot 教示把持動作スキル学習システム, in 第40回日本ロボット学会学術講演会講演論文集 (RSJ22J), 3F1-03, 2022.</li><li><strong>金沢 直晃</strong>, 河原塚 健人, 岡田 慧, 稲葉 雅幸.
Parametric Bias を用いた食材特徴を考慮可能な調理ロボットの包丁切断操作学習, in 第40回日本ロボット学会学術講演会講演論文集 (RSJ22J), 4I1-06, 2022.</li><li><strong>金沢 直晃</strong>, 河原塚 健人, 岡田 慧, 稲葉 雅幸.
Parametric Bias を用いた食材特徴を考慮可能な調理ロボットの包丁切断操作学習, in 第40回日本ロボット学会学術講演会講演論文集 (RSJ22J), 4I1-06, 2022.</li><li><strong>金沢 直晃</strong>, 河原塚 健人, 岡田 慧, 稲葉 雅幸.
Parametric Biasを用いた調理ロボットの包丁切断操作における食材特徴学習, in 日本機械学会ロボティクス・メカトロニクス講演会'22 講演論文集 (ROBOMECH22J), 1A1-T11, 2022.</li><li><strong>金沢 直晃</strong>, 北川 晋吾, 室岡 貴之, 岡田 慧, 稲葉 雅幸.
テンプレートマッチング認識とプリミティブ動作により状態を考慮した家電操作を行うロボットシステム, in 第22回SICEシステムインテグレーション部門講演会講演概要集 (SI21J), 1G2-02, 2021. <strong>優秀講演賞</strong></li><li><strong>金沢 直晃</strong>, 岡田 慧, 稲葉 雅幸.
台車移動型双腕ロボットによるカレー調理行動実行システム, in 第39回日本ロボット学会学術講演会講演論文集 (RSJ21J), 2H3-05, 2021.</li><li><strong>金沢 直晃</strong>, 北川 晋吾, 室岡 貴之, 岡田 慧, 稲葉 雅幸.
調理道具を扱う双腕ロボットによる野菜皮剥き切断操作の認識行動実現システム,
in 第21回SICEシステムインテグレーション部門講演会講演概要集 (SI20J), 3E2-08, 2020.</li></ol><h2 id=awards-publication>Awards (Publication)
<a class=heading-link href=#awards-publication><i class="fa fa-link" aria-hidden=true title="Link to heading"></i>
<span class=sr-only>Link to heading</span></a></h2><ol><li><p>K. Kawaharazuka, <strong>N. Kanazawa</strong>, K. Okada, M. Inaba.
<strong>SICE International Young Authors Award (SIYA-IROS2022)</strong>, IEEE Robotics and Automation Letters (RAL), 2022.10.26.</p></li><li><p><strong>金沢 直晃</strong>, 北川 晋吾, 室岡 貴之, 岡田 慧, 稲葉 雅幸.
<strong>優秀講演賞</strong>, 第22回 計測自動制御学会 システムインテグレーション部門講演会 (SI2021) 2021.12.24.</p></li></ol><h2 id=awards-and-experiences-others>Awards and Experiences (Others)
<a class=heading-link href=#awards-and-experiences-others><i class="fa fa-link" aria-hidden=true title="Link to heading"></i>
<span class=sr-only>Link to heading</span></a></h2><ol><li>Team JSK: Y. Obinata, <strong>N. Kanazawa</strong>, S. Kim, K. Kawaharazuka, I. Yanokura, S. Kitagawa. <strong>First Place (GPSR task in DSPL)</strong>, RoboCup@Home JapanOpen2022, 2023.03.06-09.</li><li>Team 4: 稲富翔伍, <strong>金沢直晃</strong>, 牧原昂志, 籾山陽紀, 渡部泰樹(五十音順). &ldquo;柔軟物体操作のための世界モデルの構築と実環境への適用可能性の検証&rdquo;, <strong>最優秀賞</strong>, 東京大学 集中講義 世界モデルと知能 最終課題発表会 口頭発表, 2022.05.25. <a href=https://world-model.t.u-tokyo.ac.jp/ class=external-link target=_blank rel=noopener>Link</a></li><li>SFP2019黒板消しロボットチーム, <strong>チームラボ賞</strong>, GUGEN2019.12.08. <a href=https://gugen.jp/result/2019.html class=external-link target=_blank rel=noopener>Link</a>, <a href=https://gugen.jp/subscriptions/work/871 class=external-link target=_blank rel=noopener>Product Link</a></li><li><strong>twilio 賞</strong>, TRUNK HACKATHON in OSAKA 2019. 2019.03.16-17.</li></ol></article></section></div><footer class=footer><section class=container>©
2023
Naoaki Kanazawa
·
Powered by <a href=https://gohugo.io/ target=_blank rel=noopener>Hugo</a> & <a href=https://github.com/luizdepra/hugo-coder/ target=_blank rel=noopener>Coder</a>.</section></footer></main><script src=/js/coder.min.6ae284be93d2d19dad1f02b0039508d9aab3180a12a06dcc71b0b0ef7825a317.js integrity="sha256-auKEvpPS0Z2tHwKwA5UI2aqzGAoSoG3McbCw73gloxc="></script></body></html>